{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random \n",
    "import cv2\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "_\n",
    "training_file = \"./train.p\"\n",
    "testing_file = \"./test.p\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train_o, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value.\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train_o)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = (X_train_o[0].shape)\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "#count of each type image\n",
    "unique, index, counts = np.unique(y_train, return_index = True, return_counts=True)\n",
    "#print (np.asarray((unique, counts, index)).T.shape)\n",
    "#print (np.sum(counts))\n",
    "#print (np.asarray((unique, index, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of each type image\n",
    "unique, index, counts = np.unique(y_train, return_index = True,\n",
    "                                  return_counts=True)\n",
    "print (\"unique\", unique)\n",
    "print (\"counts\", counts)\n",
    "print (\"index\", index)\n",
    "\n",
    "# print (np.asarray((unique, counts, index)).T.shape)\n",
    "print (np.sum(counts))\n",
    "print (np.asarray((unique, index, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the bar graph of the frequency of classes \n",
    "plt.bar(unique, counts, 1)\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "\n",
    "index1 = random.randint(0,len(X_train_o))\n",
    "image1 = X_train_o[index1].squeeze()\n",
    "index2 = 19\n",
    "image2 = X_train_o[index2].squeeze()\n",
    "\n",
    "\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(image1, cmap = 'gray')\n",
    "print (y_train[index1])\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(image2, cmap = 'gray')\n",
    "print (y_train[index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the different class of signs \n",
    "\n",
    "with open('signnames.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    class_names = dict(reader)\n",
    "\n",
    "# choose one sample to use for visualization from each class\n",
    "sample_class_image = []\n",
    "for n in range(n_classes):\n",
    "    sample_class_image.append(np.random.choice(np.where(y_train==n)[0]))\n",
    "\n",
    "\n",
    "show_samples = X_train_o[sample_class_image,:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot classes in a grid\n",
    "\n",
    "# function to plot sample images in a grid\n",
    "def plot_classes(box, grid_w, grid_h, stitch_layers=True):\n",
    "    fig = plt.figure()\n",
    "    for j in range(box.shape[0]):\n",
    "        ax = fig.add_subplot(grid_h, grid_w, j+1)\n",
    "        ax.imshow(box[j].squeeze(), cmap = 'gray')\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(show_samples, 8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the the training images to grayscale\n",
    "X_train = []\n",
    "for i in range (np.shape(X_train_o)[0]):\n",
    "    img = cv2.cvtColor(X_train_o[i,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "    img = img.squeeze()\n",
    "    img = img.reshape(32,32,1)\n",
    "    X_train.append(img)\n",
    "    \n",
    "# show a sample image converted\n",
    "plt.imshow(X_train[1000].squeeze(), cmap = 'gray')\n",
    "plt.title('Sample Gray Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the image\n",
    "def transform_image(img,ang_range,shear_range,trans_range):\n",
    "    # Rotation\n",
    "    # generating ang_rotation rondamly and let this angle takes - values \n",
    "    # by subtracting it from the ang_range it self \n",
    "    ang_rot = np.random.uniform(ang_range)-ang_range/2\n",
    "    #print (img.shape)\n",
    "    # then we will sort the rows, cols, ch from the shape of the images \n",
    "    # becuase those parameters are feed to the rotation Translation Shear\n",
    "    #funtion using the\n",
    "    # using the opencv library \n",
    "    rows,cols,ch = img.shape\n",
    "    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)\n",
    "\n",
    "    # Translation\n",
    "    # same as here we will generate a rondom values for the transilation \n",
    "    # as we know our image is gray scale image that means a 2D matrix \n",
    "    # that means the transilation will be only  x band y direction \n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    tr_y = trans_range*np.random.uniform()-trans_range/2\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "\n",
    "    # Shear\n",
    "    pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "\n",
    "    pt1 = 5+shear_range*np.random.uniform()-shear_range/2\n",
    "    pt2 = 20+shear_range*np.random.uniform()-shear_range/2\n",
    "\n",
    "    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "\n",
    "    shear_M = cv2.getAffineTransform(pts1,pts2)\n",
    "        \n",
    "    img = cv2.warpAffine(img,Rot_M,(cols,rows))\n",
    "    img = cv2.warpAffine(img,Trans_M,(cols,rows))\n",
    "    img = cv2.warpAffine(img,shear_M,(cols,rows))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "total_images_per_set = 2500\n",
    "for i in range(n_classes):\n",
    "    print (i),\n",
    "    to_loop = int((total_images_per_set-counts[i])/100)\n",
    "#    print (to_loop+1)\n",
    "#    print (index[i])\n",
    "#    print (counts[i])\n",
    "    if to_loop < 0:\n",
    "        continue\n",
    "    for j in range(to_loop+1):\n",
    "        m = random.randint(index[i],index[i] + counts[i]-1)\n",
    "#        print (\"m = \",m)\n",
    "        index2 = m\n",
    "        #print (X_train[index2].shape)\n",
    "        #image2 = X_train[index2].squeeze()\n",
    "        image2 = X_train[index2]\n",
    "        for k in range(100):\n",
    "            img = transform_image(image2,10,10,5)\n",
    "            img = img.reshape(1,32,32,1)\n",
    "            X_train = np.concatenate((X_train,img), axis = 0)\n",
    "            y_train = np.append(y_train,unique[i])\n",
    "\n",
    "print (\"Transformation process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the size of the data and counts of X_train_augmented\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = (X_train[0].shape)\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "#count of each type image\n",
    "unique, index, counts = np.unique(y_train, return_index = True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(unique, counts, 1)\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data in the file for future use\n",
    "train_augmented_file = \"./traffic-signs-data/train_augmented_gray.p\" \n",
    "output = open(train_augmented_file, 'wb')\n",
    "\n",
    "mydict2 = {'features': 1, 'labels': 2}\n",
    "mydict2['features'] = X_train\n",
    "mydict2['labels'] = y_train\n",
    "pickle.dump(mydict2, output)\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize dataset\n",
    "X_train = (np.array(X_train) - 128.0)/256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate data additional data (OPTIONAL!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "X_train, y_train = shuffle(X_train,y_train)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (len(X_train), len(y_train))\n",
    "print (len(X_validation),len(y_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def SignTraffic(x, keep_prob):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    #Layer1 32*32*1 --> 28*28*16 \n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5,5,1,16), mean = mu, stddev = sigma), name = 'conv1_W')\n",
    "    conv1_b = tf.Variable(tf.constant(0.1, shape = [16]), name = 'conv1_b')\n",
    "    conv1 = tf.add(tf.nn.conv2d(x,conv1_W, strides = [1,1,1,1], padding = 'VALID') , conv1_b)\n",
    "    #Layer1 activation \n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    #Layer1 pooling 28*28*16 --> 14*14*16\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    #Layer2  14*14*16 --> 10*10*32\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5,5,16,32), mean = mu , stddev = sigma), name = 'conv2_W')\n",
    "    conv2_b = tf.Variable(tf.constant(0.1, shape = [32]), name = 'conv2_b')\n",
    "    conv2 = tf.add(tf.nn.conv2d(conv1, conv2_W, strides = [1,1,1,1], padding = 'VALID') , conv2_b)\n",
    "    #Layer2 activation\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    #Later2 pooling 10*10*32 --> 5*5*32 \n",
    "    conv2 = tf.nn.max_pool(conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    #Flatten 5*5*32 --> 800 \n",
    "    fc0 = flatten(conv2)\n",
    "    \n",
    "    #Layer3  800--> 516\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape = (800,516), mean = mu , stddev = sigma), name = 'fc1_W')\n",
    "    fc1_b = tf.Variable(tf.constant(0.1, shape = [516]), name = 'fc1_b')\n",
    "    fc1 = tf.add(tf.matmul(fc0, fc1_W) , fc1_b)\n",
    "    #Layer3 activation\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    #Dropout \n",
    "    fc1 = tf.nn.dropout(fc1,keep_prob)\n",
    "    \n",
    "    \n",
    "    #Layer4 516--> 360\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape = (516,360), mean = mu , stddev = sigma), name = 'fc2_W')\n",
    "    fc2_b = tf.Variable(tf.constant(0.1, shape = [360]), name = 'fc2_b')\n",
    "    fc2 = tf.add(tf.matmul(fc1,fc2_W) , fc2_b)\n",
    "    #Layer4 activation\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    \n",
    "    #Dropout \n",
    "    fc2 = tf.nn.dropout(fc2,keep_prob)\n",
    "    \n",
    "    #Layer5 360--> 43\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape = (360,43), mean = mu, stddev = sigma), name = 'fc3_W')\n",
    "    fc3_b = tf.Variable(tf.constant(0.1, shape =[43]), name = 'fc3_b')\n",
    "    logits = tf.add(tf.matmul(fc2,fc3_W) , fc3_b)\n",
    "    \n",
    "    return logits \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "save_file = 'saved/sign_classify.ckpt'\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y,43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning\n",
    "starttime = time.clock()\n",
    "rate = 0.001\n",
    "logits = SignTraffic(x,keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=one_hot_y)\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits( logits=prediction, labels=target_output)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation \n",
    "correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(one_hot_y,1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "all_saver = tf.train.Saver(save_relative_paths=True)\n",
    "# saver = tf.train.Saver(save_relative_paths=True)\n",
    "def evaluate(X_data, y_data, keep_prob):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0,num_examples,BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict = {x:batch_x, y:batch_y, keep_prob : 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    print (\"Training...\")\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train,y_train)\n",
    "        for offset in range (0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset : end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict = {x: batch_x, y: batch_y, keep_prob : 0.25})\n",
    "        validation_accuracy = evaluate(X_validation, y_validation, keep_prob)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "\n",
    "\n",
    "    print(\"Model saved\")\n",
    "\n",
    "    \n",
    "endtime = time.clock()\n",
    "print(\"execution took\",endtime-starttime,\"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy = {:.3f}\".format(validation_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    path=saver.save(sess,\"saved/sign_classify.ckpt\" )\n",
    "\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model here, clear the previous model\n",
    "\n",
    "drop_prob = 1.0\n",
    "#convert to gray scale images\n",
    "X_test_gray = []\n",
    "for i in range (np.shape(X_test)[0]):\n",
    "    img = cv2.cvtColor(X_test[i,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "    img = img.squeeze()\n",
    "    img = img.reshape(32,32,1)\n",
    "    X_test_gray.append(img)\n",
    "\n",
    "# normalize dataset [naive]\n",
    "X_test_gray = (np.array(X_test_gray) - 128.0)/256.0\n",
    "\n",
    "print (X_test.shape)\n",
    "print (X_test_gray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     saver.restore(sess, \"C:/Users/El Holandy/AppData/Roaming/SPB_Data/saved_data_sign_class/data_lastt.ckpt\"  )\n",
    "\n",
    "    saver.restore(sess, \"saved/sign_classify.ckpt\"  )\n",
    "\n",
    "    test_accuracy = evaluate(X_test_gray, y_test, keep_prob )\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_imgs = 25\n",
    "disp_imgs = []\n",
    "disp_imgs_gray = []\n",
    "for n in range(no_of_imgs):\n",
    "    image = cv2.imread('model_traffic_signs/'+str(n+1)+'.jpg')\n",
    "    dim = (32,32)\n",
    "\n",
    "    resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "    resized = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    disp_imgs.append(np.asarray(resized))\n",
    "    \n",
    "    resized = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)\n",
    "    disp_imgs_gray.append(np.asarray(resized))\n",
    "\n",
    "# normalize new test data\n",
    "test_imgs_gray = ((np.array(disp_imgs_gray)-128.0)/256.0).reshape(no_of_imgs,32,32,1)\n",
    "#See the different class of signs \n",
    "\n",
    "with open('signnames.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    class_names = dict(reader)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     new_saver = tf.train.import_meta_graph('sign_classify.ckpt.meta')\n",
    "#\"C:/Users/El Holandy/AppData/Roaming/SPB_Data/saved_data_sign_class/data_lastt.ckpt\" \n",
    "#     new_saver = tf.train.import_meta_graph('./saved_data_sign_class/data_lastt.ckpt.meta')\n",
    "    new_saver = tf.train.import_meta_graph('./saved/sign_classify.ckpt.meta')\n",
    "\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    # model evaluation\n",
    "    prediction = tf.argmax(logits, 1)\n",
    "\n",
    "    test_prediction = sess.run(\n",
    "        prediction,\n",
    "        feed_dict={x: test_imgs_gray, keep_prob: drop_prob})\n",
    "for i in range(no_of_imgs):\n",
    "    if i%5 == 0:\n",
    "        print (\" \")\n",
    "    print('Prediction: {} \\t| {}'.format(test_prediction[i], \n",
    "                                            class_names[str(test_prediction[i])]))\n",
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "# get the softmax probabilities for 3 best prediction probabilities.\n",
    "with tf.Session() as sess:\n",
    "#     new_saver = tf.train.import_meta_graph('./saved_data_sign_class/data_lastt.ckpt.meta')\n",
    "    new_saver = tf.train.import_meta_graph('./saved/sign_classify.ckpt.meta')\n",
    "\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    # model evaluation\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    test_prediction = sess.run(tf.nn.top_k(\n",
    "        prediction,k=5),\n",
    "        feed_dict={x: test_imgs_gray , keep_prob: drop_prob})\n",
    "\n",
    "#print('Predictions: {}'.format(test_prediction))\n",
    "# plot visualization of softmax probabilities\n",
    "index = np.arange(5)\n",
    "probabilities, predict_classes = test_prediction\n",
    "\n",
    "candidates = [4,5,12,15,22]\n",
    "for i,im in enumerate(candidates):\n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(disp_imgs[im])\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.barh(index, probabilities[im], height=0.5, align='center')\n",
    "    plt.yticks(index,[class_names[str(predict_classes[im][j])] for j in index] )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "# get the softmax probabilities for 3 best prediction probabilities.\n",
    "with tf.Session() as sess:\n",
    "#     new_saver = tf.train.import_meta_graph('./saved_data_sign_class/data_lastt.ckpt.meta')\n",
    "    new_saver = tf.train.import_meta_graph('./saved/sign_classify.ckpt.meta')\n",
    "\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    # model evaluation\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    test_prediction = sess.run(tf.nn.top_k(\n",
    "        prediction,k=5),\n",
    "        feed_dict={x: test_imgs_gray , keep_prob: drop_prob})\n",
    "\n",
    "#print('Predictions: {}'.format(test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot visualization of softmax probabilities\n",
    "index = np.arange(5)\n",
    "probabilities, predict_classes = test_prediction\n",
    "\n",
    "candidates = [4,5,12,15,22]\n",
    "for i,im in enumerate(candidates):\n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(disp_imgs[im])\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.barh(index, probabilities[im], height=0.5, align='center')\n",
    "    plt.yticks(index,[class_names[str(predict_classes[im][j])] for j in index] )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
